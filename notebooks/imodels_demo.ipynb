{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "regression data (365, 33) classification data (192, 8)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(13)\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import plot_tree, DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from scipy.io.arff import loadarff\n",
    "\n",
    "# installable with: `pip install imodels`\n",
    "from imodels import SLIMRegressor, BayesianRuleListClassifier, RuleFitRegressor, GreedyRuleListClassifier\n",
    "from imodels import SLIMClassifier, OneRClassifier, BoostedRulesClassifier\n",
    "\n",
    "# change working directory to project root\n",
    "if os.getcwd().split('/')[-1] != 'imodels':\n",
    "    os.chdir('..')\n",
    "\n",
    "\n",
    "def get_ames_data():\n",
    "    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
    "    housing_target = housing['target'].values\n",
    "    housing_data_numeric = housing['data'].select_dtypes('number').drop(columns=['Id']).dropna(axis=1)\n",
    "    feature_names = housing_data_numeric.columns.values\n",
    "    X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "        housing_data_numeric.values, housing_target, test_size=0.75)\n",
    "    return X_train_reg, X_test_reg, y_train_reg, y_test_reg, feature_names\n",
    "    \n",
    "\n",
    "def get_diabetes_data():\n",
    "    '''load (classification) data on diabetes\n",
    "    '''\n",
    "    data = loadarff(\"tests/test_data/diabetes.arff\")\n",
    "    data_np = np.array(list(map(lambda x: np.array(list(x)), data[0])))\n",
    "    X = data_np[:, :-1].astype('float32')\n",
    "    y_text = data_np[:, -1].astype('str')\n",
    "    y = (y_text == 'tested_positive').astype(int)  # labels 0-1\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.75)  # split\n",
    "    feature_names = [\"#Pregnant\", \"Glucose concentration test\", \"Blood pressure(mmHg)\",\n",
    "                     \"Triceps skin fold thickness(mm)\",\n",
    "                     \"2-Hour serum insulin (mu U/ml)\", \"Body mass index\", \"Diabetes pedigree function\", \"Age (years)\"]\n",
    "    return X_train, X_test, y_train, y_test, feature_names\n",
    "\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg, feat_names_reg = get_ames_data()\n",
    "X_train, X_test, y_train, y_test, feat_names = get_diabetes_data()\n",
    "\n",
    "\n",
    "def viz_classification_preds(probs, y_test):\n",
    "    '''look at prediction breakdown\n",
    "    '''\n",
    "    plt.subplot(121)\n",
    "    plt.hist(probs[:, 1][y_test == 0], label='Class 0')\n",
    "    plt.hist(probs[:, 1][y_test == 1], label='Class 1', alpha=0.8)\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Predicted probability of class 1')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(122)\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    plt.title('ROC curve')\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, preds)\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# load some data\n",
    "print('regression data', X_train_reg.shape, 'classification data', X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rule sets\n",
    "Rule sets are models that create a set of (potentially overlapping) rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rulefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test r2: 0.63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_93c48_row0_col1, #T_93c48_row0_col2, #T_93c48_row1_col2, #T_93c48_row2_col2, #T_93c48_row3_col2 {\n",
       "  background-color: #fde725;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_93c48_row1_col1, #T_93c48_row2_col1, #T_93c48_row3_col1, #T_93c48_row9_col1 {\n",
       "  background-color: #2c728e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_93c48_row4_col1 {\n",
       "  background-color: #2c718e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_93c48_row4_col2 {\n",
       "  background-color: #2ab07f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_93c48_row5_col1, #T_93c48_row9_col2 {\n",
       "  background-color: #440154;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_93c48_row5_col2 {\n",
       "  background-color: #20928c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_93c48_row6_col1 {\n",
       "  background-color: #453781;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_93c48_row6_col2 {\n",
       "  background-color: #2b748e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_93c48_row7_col1 {\n",
       "  background-color: #33628d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_93c48_row7_col2 {\n",
       "  background-color: #2c738e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_93c48_row8_col1 {\n",
       "  background-color: #482173;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_93c48_row8_col2 {\n",
       "  background-color: #2d708e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_93c48_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >rule</th>\n",
       "      <th class=\"col_heading level0 col1\" >coef</th>\n",
       "      <th class=\"col_heading level0 col2\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_93c48_level0_row0\" class=\"row_heading level0 row0\" >2</th>\n",
       "      <td id=\"T_93c48_row0_col0\" class=\"data row0 col0\" >OverallQual</td>\n",
       "      <td id=\"T_93c48_row0_col1\" class=\"data row0 col1\" >16444.208788</td>\n",
       "      <td id=\"T_93c48_row0_col2\" class=\"data row0 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93c48_level0_row1\" class=\"row_heading level0 row1\" >9</th>\n",
       "      <td id=\"T_93c48_row1_col0\" class=\"data row1 col0\" >TotalBsmtSF</td>\n",
       "      <td id=\"T_93c48_row1_col1\" class=\"data row1 col1\" >0.299887</td>\n",
       "      <td id=\"T_93c48_row1_col2\" class=\"data row1 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93c48_level0_row2\" class=\"row_heading level0 row2\" >13</th>\n",
       "      <td id=\"T_93c48_row2_col0\" class=\"data row2 col0\" >GrLivArea</td>\n",
       "      <td id=\"T_93c48_row2_col1\" class=\"data row2 col1\" >32.150210</td>\n",
       "      <td id=\"T_93c48_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93c48_level0_row3\" class=\"row_heading level0 row3\" >23</th>\n",
       "      <td id=\"T_93c48_row3_col0\" class=\"data row3 col0\" >GarageArea</td>\n",
       "      <td id=\"T_93c48_row3_col1\" class=\"data row3 col1\" >18.784050</td>\n",
       "      <td id=\"T_93c48_row3_col2\" class=\"data row3 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93c48_level0_row4\" class=\"row_heading level0 row4\" >37</th>\n",
       "      <td id=\"T_93c48_row4_col0\" class=\"data row4 col0\" >1stFlrSF <= 1417.0</td>\n",
       "      <td id=\"T_93c48_row4_col1\" class=\"data row4 col1\" >-53.821871</td>\n",
       "      <td id=\"T_93c48_row4_col2\" class=\"data row4 col2\" >0.731507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93c48_level0_row5\" class=\"row_heading level0 row5\" >36</th>\n",
       "      <td id=\"T_93c48_row5_col0\" class=\"data row5 col0\" >OverallQual <= 7.5 and TotalBsmtSF <= 1201.0</td>\n",
       "      <td id=\"T_93c48_row5_col1\" class=\"data row5 col1\" >-9939.848976</td>\n",
       "      <td id=\"T_93c48_row5_col2\" class=\"data row5 col2\" >0.641096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93c48_level0_row6\" class=\"row_heading level0 row6\" >34</th>\n",
       "      <td id=\"T_93c48_row6_col0\" class=\"data row6 col0\" >GrLivArea <= 1790.0 and YearBuilt <= 1994.5</td>\n",
       "      <td id=\"T_93c48_row6_col1\" class=\"data row6 col1\" >-5774.881924</td>\n",
       "      <td id=\"T_93c48_row6_col2\" class=\"data row6 col2\" >0.550685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93c48_level0_row7\" class=\"row_heading level0 row7\" >35</th>\n",
       "      <td id=\"T_93c48_row7_col0\" class=\"data row7 col0\" >GrLivArea <= 1789.5 and TotalBsmtSF <= 1199.5</td>\n",
       "      <td id=\"T_93c48_row7_col1\" class=\"data row7 col1\" >-1774.730136</td>\n",
       "      <td id=\"T_93c48_row7_col2\" class=\"data row7 col2\" >0.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93c48_level0_row8\" class=\"row_heading level0 row8\" >33</th>\n",
       "      <td id=\"T_93c48_row8_col0\" class=\"data row8 col0\" >GrLivArea <= 1928.5 and TotalBsmtSF <= 1089.0</td>\n",
       "      <td id=\"T_93c48_row8_col1\" class=\"data row8 col1\" >-7556.897729</td>\n",
       "      <td id=\"T_93c48_row8_col2\" class=\"data row8 col2\" >0.536986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93c48_level0_row9\" class=\"row_heading level0 row9\" >38</th>\n",
       "      <td id=\"T_93c48_row9_col0\" class=\"data row9 col0\" >1stFlrSF > 1417.0</td>\n",
       "      <td id=\"T_93c48_row9_col1\" class=\"data row9 col1\" >0.000000</td>\n",
       "      <td id=\"T_93c48_row9_col2\" class=\"data row9 col2\" >0.268493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x125915d30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a rulefit model\n",
    "rulefit = RuleFitRegressor(max_rules=10)\n",
    "rulefit.fit(X_train_reg, y_train_reg, feature_names=feat_names_reg)\n",
    "\n",
    "# get test performance\n",
    "preds = rulefit.predict(X_test_reg)\n",
    "print(f'test r2: {metrics.r2_score(y_test_reg, preds):0.2f}')\n",
    "\n",
    "# inspect and print the rules\n",
    "rules = rulefit.get_rules()\n",
    "rules = rules[rules.coef != 0].sort_values(\"support\", ascending=False)\n",
    "\n",
    "# 'rule' is how the feature is constructed\n",
    "# 'coef' is its weight in the final linear model\n",
    "# 'support' is the fraction of points it applies to\n",
    "rules[['rule', 'coef', 'support']].style.background_gradient(cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boosted stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit boosted stumps\n",
    "brc = BoostedRulesClassifier(n_estimators=10)\n",
    "brc.fit(X_train, y_train, feature_names=feat_names)\n",
    "\n",
    "print(brc)\n",
    "\n",
    "# look at performance\n",
    "probs = brc.predict_proba(X_test)\n",
    "viz_classification_preds(probs, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rule lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### greedy rule lists\n",
    "**like a decision tree that only ever splits going left**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# fit a greedy rule list\n",
    "m = GreedyRuleListClassifier()\n",
    "m.fit(X_train, y=y_train, feature_names=feat_names)  # stores into m.rules_\n",
    "probs = m.predict_proba(X_test)\n",
    "\n",
    "# print the list\n",
    "print(m)\n",
    "\n",
    "# look at prediction breakdown\n",
    "viz_classification_preds(probs, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oneR\n",
    "**fits a rule list restricted to use only one feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a oneR model\n",
    "m = OneRClassifier()\n",
    "m.fit(X_train, y=y_train, feature_names=feat_names)  # stores into m.rules_\n",
    "probs = m.predict_proba(X_test)\n",
    "\n",
    "# print the rule list\n",
    "print(m)\n",
    "\n",
    "# look at prediction breakdown\n",
    "viz_classification_preds(probs, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scalable bayesian rule lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier (allow more iterations for better accuracy; use BigDataRuleListClassifier for large datasets)\n",
    "print('training...')\n",
    "m = BayesianRuleListClassifier(max_iter=3000, class1label=\"diabetes\", verbose=False)\n",
    "m.fit(X_train, y_train)\n",
    "probs = m.predict_proba(X_test)\n",
    "print(\"learned model:\\n\", m)\n",
    "viz_classification_preds(probs, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rule trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### short decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# specify a decision tree with a maximum depth\n",
    "dt = DecisionTreeClassifier(max_depth=3)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# calculate mse on the training data\n",
    "probs = dt.predict_proba(X_test)\n",
    "# print(f'test mse: {np.mean(np.square(preds-y)):0.2f}')\n",
    "\n",
    "plot_tree(dt)\n",
    "# plt.savefig('tree.pdf')\n",
    "plt.show()\n",
    "\n",
    "viz_classification_preds(probs, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimal classification tree\n",
    "- docs [here](https://github.com/csinva/interpretability-workshop/tree/master/imodels/optimal_classification_tree)\n",
    "- note: this implementation is still somewhat unstable, and can be made faster by installing either `cplex` or `gurobi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append('../imodels/optimal_classification_tree/pyoptree')\n",
    "# sys.path.append('../imodels/optimal_classification_tree/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from optree import OptimalTreeModel\n",
    "# feature_names = np.array([\"x1\", \"x2\"])\n",
    "\n",
    "# X = np.array([[1, 2, 2, 2, 3], [1, 2, 1, 0, 1]]).T\n",
    "# y = np.array([1, 1, 0, 0, 0]).reshape(-1, 1)\n",
    "# X_test = np.array([[1, 1, 2, 2, 2, 3, 3], [1, 2, 2, 1, 0, 1, 0]]).T\n",
    "# y_test = np.array([1, 1, 1, 0, 0, 0, 0])\n",
    "\n",
    "# np.random.seed(13)\n",
    "# model = OptimalTreeModel(tree_depth=3, N_min=1, alpha=0.1) #, solver_name='baron'\n",
    "# model.fit(X_test, y_test) # this method is currently using the fast, but not optimal solver\n",
    "# preds = model.predict(X_test)\n",
    "\n",
    "# # fit on the bigger diabetes dset from above\n",
    "# # model.fit(Xtrain, ytrain) # this method is currently using the fast, but not optimal solver\n",
    "# # preds = model.predict(Xtest)\n",
    "\n",
    "# print('acc', np.mean(preds == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.print_tree(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# algebraic models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### integer linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# generate X and y\n",
    "n, p = 500, 10\n",
    "X_sim = np.random.randn(n, p)\n",
    "y_sim = 1 * X_sim[:, 0] + 2 * X_sim[:, 1] - 1 * X_sim[:, 2] + np.random.randn(n)\n",
    "\n",
    "# fit linear models with different regularization parameters\n",
    "print('groundtruth weights should be 1, 2, -1...')\n",
    "model = SLIMRegressor()\n",
    "for lambda_reg in [1e-3, 1e-2, 5e-2, 1e-1, 1, 2, 5, 10]:\n",
    "    model.fit(X_sim, y_sim, lambda_reg)\n",
    "    mse = np.mean(np.square(y_sim - model.predict(X_sim)))\n",
    "    print(f'lambda: {lambda_reg}\\tmse: {mse: 0.2f}\\tweights: {model.model_.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sim = 1 / (1 + np.exp(-y_sim))\n",
    "y_sim = np.round(y_sim)\n",
    "\n",
    "# fit linear models with different regularization parameters\n",
    "print('groundtruth weights should be 1, 2, -1...')\n",
    "model = SLIMClassifier()\n",
    "for lambda_reg in [1e-3, 1e-2, 5e-2, 1e-1, 1, 2, 5, 10]:\n",
    "    model.fit(X_sim, y_sim, lambda_reg)\n",
    "    mll = np.mean(metrics.log_loss(y_sim, model.predict(X_sim)))\n",
    "    print(f'lambda: {lambda_reg}\\tmlogloss: {mll: 0.2f}\\tweights: {model.model_.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,../imodels/tests/notebooks//py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
